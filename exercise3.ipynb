{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACTS: <br>\n",
    "Number of images in training set: N = 416 <br>\n",
    "Number of Pixels per image: D = 2576 <br>\n",
    "Number of classes: c = 52 <br>\n",
    "-> <br>\n",
    "Sw: rank(Sw)= N-c = 364 -> Mpca <= 364 <br>\n",
    "Sb: rank(Sb)= c-1 = 51 -> Mlda <= 51 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5eba1df5c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTRAIN_RATIO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mCLASS_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mPIC_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dimensions of picture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPIC_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIC_DIM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mPIC_DIM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face_label' is not defined"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "TRAIN_RATIO = 0.8\n",
    "CLASS_SIZE = np.amax(face_label) # number of classes\n",
    "PIC_DIM = (46,56) # dimensions of picture\n",
    "PIC_SIZE = PIC_DIM[0]*PIC_DIM[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing sets: 80% is training, 20% is testing\n",
    "\n",
    "splittype = 'whole'\n",
    "\n",
    "if (splittype == 'whole'):\n",
    "    training = np.loadtxt('split_whole_train.gzip', dtype = 'uint8')\n",
    "    test = np.loadtxt('split_whole_test.gzip', dtype = 'uint8')\n",
    "elif (splittype == 'class'):\n",
    "    training = np.loadtxt('split_class_train.gzip', dtype = 'uint8')\n",
    "    test = np.loadtxt('split_class_test.gzip', dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training, testing: axis 0: pictures, axis 1: pixels + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order training data depending on their class\n",
    "training = training[np.argsort(training[:,-1]),:]\n",
    "\n",
    "# Create a list of arrays depending on the classes\n",
    "class_sets = []\n",
    "for i in range(52):\n",
    "    class_sets.append(training[i==(training[:,-1]-1),:2576])\n",
    "    \n",
    "print(class_sets[0],class_sets[0].shape)\n",
    "\n",
    "# Calculate the class means\n",
    "#class_means = []\n",
    "#for c in class_sets:\n",
    "#    class_means.append(np.mean(c, axis=0))\n",
    "#print(class_means[0],class_means[0].shape)\n",
    "\n",
    "class_means = np.zeros((52,2576))\n",
    "for i in range(52):\n",
    "    class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "# Calculate the global mean\n",
    "global_mean = np.mean(training[:,:2576], axis=0)\n",
    "print(global_mean,global_mean.shape)\n",
    "\n",
    "#Calculate Sb\n",
    "class_means_norm = class_means - global_mean #make us of broadcasting\n",
    "Sb = np.dot(class_means_norm.T, class_means_norm)\n",
    "#print(np.linalg.matrix_rank(Sb)) # =c-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate x-mi\n",
    "class_sets_norm = []\n",
    "for i in range(52):\n",
    "    class_sets_norm.append(class_sets[i]-class_means[i,:])\n",
    "print(class_sets_norm[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Sw\n",
    "Sw = np.zeros((2576,2576))\n",
    "for c in class_sets_norm:\n",
    "    Sw += np.dot(c.T,c)\n",
    "    \n",
    "#print(np.linalg.matrix_rank(Sw)) # = N-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate St\n",
    "# Images are represented as rows of the array 'pca_train'\n",
    "pca_train = training [:, :2576]\n",
    "pca_train_norm = pca_train - global_mean\n",
    "St = np.dot(pca_train_norm.T, pca_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Wpca\n",
    "eigvals_St, eigvecs_St = np.linalg.eig(St)\n",
    "\n",
    "# take real part of the eigenvalues (complex eigenvalues are the result of calculation rounding errors)\n",
    "eigvals_St = np.real(eigvals_St)\n",
    "eigvecs_St = np.real(eigvecs_St)\n",
    "\n",
    "#order eigenvectors and eigenvalues according to their size\n",
    "index_St = eigvals_St.argsort()[::-1]\n",
    "eigvals_St = eigvals_St[index_St]\n",
    "eigvecs_St = eigvecs_St[:,index_St]\n",
    "\n",
    "# We just keep the first n eigenvectors and eigenvalues\n",
    "Mpca = 350 #<=364\n",
    "eigvecs_St_best = eigvecs_St[:, :Mpca]\n",
    "eigvals_St_best = eigvals_St[:Mpca]\n",
    "\n",
    "#Define Wpca\n",
    "Wpca = eigvecs_St_best\n",
    "\n",
    "print(Wpca, Wpca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inverse of Sw_reduced times Sb_reduced\n",
    "LDA = np.linalg.inv(Wpca.T.dot(Sw).dot(Wpca)).dot(Wpca.T.dot(Sb).dot(Wpca))\n",
    "\n",
    "print(LDA, LDA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Wlda\n",
    "#Get the generalised eigenvectors of LDA_matrix with largest Mlda eigenvalues\n",
    "eigvals_LDA, eigvecs_LDA = np.linalg.eig(LDA)\n",
    "\n",
    "# take real part of the eigenvalues (complex eigenvalues are the result of calculation rounding errors)\n",
    "eigvals_LDA = np.real(eigvals_LDA)\n",
    "eigvecs_LDA = np.real(eigvecs_LDA)\n",
    "\n",
    "#order eigenvectors and eigenvalues according to their size\n",
    "index_LDA = eigvals_LDA.argsort()[::-1]\n",
    "eigvals_LDA = eigvals_LDA[index_LDA]\n",
    "eigvecs_LDA = eigvecs_LDA[:,index_LDA]\n",
    "\n",
    "x = np.arange(0, 350)\n",
    "print (eigvals_LDA, eigvals_LDA.shape)\n",
    "\n",
    "# plot them\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(x, eigvals_LDA) # clearly out of scale, so let's just take the first 200 of them\n",
    "plt.title('All eigenvalues of the covariance matrix')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(x[:200], eigvals_LDA[:200]) # still out of scale, so let's just take the first 20 of them\n",
    "plt.title('First 200 eigenvalues of the covariance matrix')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(x[:20], eigvals_LDA[:20])\n",
    "plt.title('First 20 eigenvalues of the covariance matrix')\n",
    "plt.show()\n",
    "\n",
    "# We just keep the first Mlda eigenvectors and eigenvalues\n",
    "Mlda = 50 #<=51\n",
    "eigvecs_LDA_best = eigvecs_LDA[:, :Mlda]\n",
    "eigvals_LDA_best = eigvals_LDA[:Mlda]\n",
    "\n",
    "#Define Wpca\n",
    "Wlda = eigvecs_LDA_best\n",
    "\n",
    "print(Wlda, Wlda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Wopt\n",
    "Wopt_transposed = Wlda.T.dot(Wpca.T)\n",
    "print(Wopt_transposed,Wopt_transposed.shape)\n",
    "Wopt = Wopt_transposed.T\n",
    "plt.imshow(np.reshape(Wopt[:,0], (46,56)).T, cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruction check\n",
    "plt.imshow(np.reshape(pca_train[0,:], (46,56)).T, cmap = 'gist_gray')\n",
    "pic_LDA = Wopt_transposed.dot((pca_train[0,:]-global_mean))\n",
    "pic_LDA_reconstructed = Wopt.dot(pic_LDA)+global_mean\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(pic_LDA_reconstructed, (46,56)).T, cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the class for the test set\n",
    "#Project train data into LDA space\n",
    "train_norm = (training[:,:2576] - global_mean).T \n",
    "print(train_norm.shape) #each picture is a column\n",
    "train_LDA = Wopt_transposed.dot(train_norm)\n",
    "print(train_LDA.shape) #each picture is a column\n",
    "\n",
    "#Project test data into LDA space\n",
    "test_norm = (test[:,:2576] - global_mean).T \n",
    "print(test_norm.shape) #each picture is a column\n",
    "test_LDA = Wopt_transposed.dot(test_norm)\n",
    "print(test_LDA.shape) #each picture is a column\n",
    "\n",
    "train_LDA_reshape_1 = np.repeat(train_LDA.reshape(Mlda,416,1),104, axis=2) #axis-0: projected values, axis-1: training pictures, axis-2: repeated values\n",
    "test_LDA_reshape_1 = np.repeat(test_LDA.reshape(Mlda,1,104), 416, axis=1) #axis-0: projected values, axis-1: repeated values, axis-2: test pictures\n",
    "\n",
    "#Do nearest neighbours\n",
    "distances = np.linalg.norm(test_LDA_reshape_1-train_LDA_reshape_1, axis=0)\n",
    "print(distances.shape)\n",
    "\n",
    "#calculate the nearest training picture\n",
    "nearest_trainpicture = distances.argmin(axis=0)\n",
    "print(nearest_trainpicture)\n",
    "\n",
    "#determine the nearest classes\n",
    "classes_pred = training[nearest_trainpicture,2576]\n",
    "classes_act = test[:,2576]\n",
    "\n",
    "cm = confusion_matrix(classes_act, classes_pred)\n",
    "\n",
    "print(cm)\n",
    "plt.matshow(cm, cmap = 'Blues')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "percentage = np.sum(classes_pred==classes_act) / len(classes_act)\n",
    "print(\"Percentage: \",percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the class for the test set (average nearest neighbours)\n",
    "#Project all classes into the LDA-Space\n",
    "class_sets_LDA = []\n",
    "for c in class_sets:\n",
    "    class_sets_LDA.append(Wopt_transposed.dot((c-global_mean).T))\n",
    "print(class_sets_LDA[0], class_sets_LDA[0].shape)\n",
    "\n",
    "#calculate the average distance to the class\n",
    "class_mean_distance = np.zeros((52,104))\n",
    "for i in range(52):\n",
    "    train_LDA_reshape_2 = np.repeat(class_sets_LDA[i].reshape(Mlda,class_sets_LDA[i].shape[1],1),104,axis=2)\n",
    "    test_LDA_reshape_2 = np.repeat(test_LDA.reshape(Mlda,1,104), class_sets_LDA[i].shape[1], axis=1)\n",
    "    d = np.linalg.norm(test_LDA_reshape_2-train_LDA_reshape_2, axis=0)\n",
    "    class_mean_distance[i,:]=np.average(d,axis=0)\n",
    "    \n",
    "#class_mean_distance is a matrix where each element stores the mean class difference of a test point to a certain class\n",
    "#axis-0: classes, axis-1: mean distance for each point\n",
    "print(class_mean_distance.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the nearest classes\n",
    "classes_pred_1 = class_mean_distance.argmin(axis=0)+1 #python index starts from 0 -> add 1\n",
    "classes_act_1 = test[:,2576]\n",
    "\n",
    "cm = confusion_matrix(classes_act_1, classes_pred_1)\n",
    "\n",
    "print(cm)\n",
    "plt.matshow(cm, cmap = 'Blues')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "percentage_1 = np.sum(classes_pred_1==classes_act_1) / len(classes_act_1)\n",
    "print(\"Percentage: \",percentage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
